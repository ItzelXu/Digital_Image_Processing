


import pickle

import numpy as np

import data

import saab_compact as saab

import keras

import sklearn





def main():



​    num_sample = 300

​    \# load data

​    fr = open('pca_params_compact.pkl', 'rb')

​    pca_params = pickle.load(fr)

​    fr.close()



​    \# read data

​    train_images, train_labels, test_images, test_labels, class_list = data.import_data("0-9")

​    train_images = train_images[:num_sample]

​    train_labels = train_labels[:num_sample]

​    print('Training image size: dtype: ', train_images.shape, train_images.dtype)

​    print('Testing_image size:', test_images.shape)



​    \# Training

​    print('--------Training--------')

​    train_images=np.moveaxis(train_images, 3, 1)

​    feature = saab.initialize(train_images, pca_params)

​    \# 60000x400 (16*5*5)

​    feature = feature.reshape(feature.shape[0], -1)

​    print("S4 shape:", feature.shape)

​    print('--------Finish Feature Extraction subnet--------')

​    print ('feature.dtype: {}'.format(feature.dtype))

​    feat = {}

​    feat['feature'] = feature



​    \# save data

​    fw = open('feat_compact.pkl', 'wb')

​    pickle.dump(feat, fw)

​    fw.close()





if __name__ == '__main__':

​    main()



import keras

from keras.datasets import mnist

import numpy as np

import saab_compact as saab



def get_data_for_class(images, labels, cls):

​	if type(cls)==list:

​		idx=np.zeros(labels.shape, dtype=bool)

​		for c in cls:

​			idx=np.logical_or(idx, labels==c)

​	else:

​		idx=(labels==cls)

​	return images[idx], labels[idx]



def import_data(use_classes):

​	(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

​	train_images=train_images.reshape(-1,28,28,1)

​	test_images=test_images.reshape(-1,28,28,1)

​	train_images=train_images/255.

​	test_images=test_images/255.



​	train_images=np.float32(train_images)

​	test_images=np.float32(test_images)



​	print( 'initiali dtype: ', train_images.dtype)

​	# print(train_images.shape) # 60000*28*28*1



​	# zeropadding

​	train_images=np.pad(train_images, ((0,0),(2,2),(2,2),(0,0)), mode='constant')

​	test_images=np.pad(test_images,  ((0,0),(2,2),(2,2),(0,0)), mode='constant')

​	# print(train_images.shape) # 60000*32*32*1



​	if use_classes!='0-9':

​		class_list=saab.parse_list_string(use_classes)

​		train_images, train_labels=get_data_for_class(train_images, train_labels, class_list)

​		test_images, test_labels=get_data_for_class(test_images, test_labels, class_list)

​		# print(class_list)

​	else:

​		class_list=[0,1,2,3,4,5,6,7,8,9]

​		

​	return train_images, train_labels, test_images, test_labels, class_list

from tensorflow.python.platform import flags

import pickle

import data

import saab_compact as saab

import numpy as np



flags.DEFINE_string("output_path", None, "The output dir to save params")

flags.DEFINE_string("use_classes", "0-9", "Supported format: 0,1,5-9")

flags.DEFINE_string("kernel_sizes", "4,4", "Kernels size for each stage. Format: '3,3'")

flags.DEFINE_string("num_kernels", "5,15", "Num of kernels for each stage. Format: '4,10'")

flags.DEFINE_float("energy_percent", None, "Energy to be preserved in each stage")

flags.DEFINE_integer("use_num_images", 600, "Num of images used for training")

FLAGS = flags.FLAGS





def main():

​    num_sample = 300

​    \# read data

​    train_images, train_labels, test_images, test_labels, class_list = data.import_data(FLAGS.use_classes)

​    

​    train_images = train_images[:num_sample]

​    train_labels = train_labels[:num_sample]

​    print('Training image size:', train_images.shape)

​    print('Testing_image size:', test_images.shape)

​    print('Training images.dtype ', train_images.dtype)



​    kernel_sizes = saab.parse_list_string(FLAGS.kernel_sizes)

​    if FLAGS.num_kernels:

​        num_kernels = saab.parse_list_string(FLAGS.num_kernels)

​    else:

​        num_kernels = None

​    energy_percent = FLAGS.energy_percent

​    use_num_images = FLAGS.use_num_images

​    print('Parameters:')

​    print('use_classes:', class_list)

​    print('Kernel_sizes:', kernel_sizes)

​    print('Number_kernels:', num_kernels)

​    print('Energy_percent:', energy_percent)

​    print('Number_use_images:', use_num_images)

​    train_images=np.moveaxis(train_images, 3, 1)

​    pca_params = saab.multi_Saab_transform(train_images, train_labels,

​                                           kernel_sizes=kernel_sizes,

​                                           num_kernels=num_kernels,

​                                           energy_percent=energy_percent,

​                                           use_num_images=use_num_images,

​                                           use_classes=class_list)

​    \# save data

​    fw = open('pca_params_compact.pkl', 'wb')

​    pickle.dump(pca_params, fw)

​    fw.close()



​    \# load data

​    fr = open('pca_params_compact.pkl', 'rb')

​    data1 = pickle.load(fr)

​    \# print(data1)

​    fr.close()





if __name__ == '__main__':

​    main()



\# running order: GetKernel.py -> pca_params for each layer

\#  GetFeature.py -> data_samples * kernels = Features

\# Getweight.py ->

import data

import pickle

import numpy as np

import sklearn

import cv2

import keras

from sklearn.decomposition import PCA

from sklearn.cluster import KMeans

from numpy import linalg as LA

import matplotlib.pyplot as plt

from sklearn.metrics.pairwise import euclidean_distances



import os



os.environ["CUDA_VISIBLE_DEVICES"] = "1"



from keras import backend as K



K.tensorflow_backend._get_available_gpus()

import random

random.seed(9001)



def main():

​    num_sample = 300

​    \# load data

​    fr = open('pca_params_compact.pkl', 'rb')

​    pca_params = pickle.load(fr)

​    fr.close()



​    \# read data

​    train_images, train_labels, test_images, test_labels, class_list = data.import_data("0-9")

​    train_images = train_images[:num_sample]

​    train_labels = train_labels[:num_sample]

​    print('Training image size:', train_images.shape)

​    print('Testing_image size:', test_images.shape)



​    \# load feature

​    fr = open('feat_compact.pkl', 'rb')

​    feat = pickle.load(fr)

​    fr.close()

​    feature = feat['feature']

​    print ('feature type: ', feature.dtype)

​    print("S4 shape:", feature.shape)

​    print('--------Finish Feature Extraction subnet--------')



​    feature=feature.reshape(num_sample, 16, 5, 5)

​    feature=np.moveaxis(feature, 1, 3)

​    feature=feature.reshape(-1, 5*5*16)



​    \# feature normalization

​    \# std_var = (np.std(feature, axis=0)).reshape(1, -1)

​    \# feature = feature / std_var



​    num_clusters = [120, 84, 10]

​    use_classes = 10

​    weights = {}

​    bias = {}

​    for k in range(len(num_clusters)):

​        if k != len(num_clusters) - 1:

​            \# Kmeans

​            kmeans = KMeans(n_clusters=num_clusters[k]).fit(feature)

​            pred_labels = kmeans.labels_

​            num_clas = np.zeros((num_clusters[k], use_classes), dtype=np.float32)

​            for i in range(num_clusters[k]):

​                for t in range(use_classes):

​                    for j in range(feature.shape[0]):

​                        if pred_labels[j] == i and train_labels[j] == t:

​                            num_clas[i, t] += 1

​            acc_train = np.sum(np.amax(num_clas, axis=1)) / feature.shape[0]

​            print(k, ' layer Kmean (just ref) training acc is {}'.format(acc_train))



​            \# Compute centroids

​            clus_labels = np.argmax(num_clas, axis=1)

​            centroid = np.zeros((num_clusters[k], feature.shape[1]), dtype=np.float32)

​            for i in range(num_clusters[k]):

​                t = 0

​                for j in range(feature.shape[0]):

​                    if pred_labels[j] == i and clus_labels[i] == train_labels[j]:

​                        if t == 0:

​                            feature_test = feature[j].reshape(1, -1)

​                        else:

​                            feature_test = np.concatenate((feature_test, feature[j].reshape(1, -1)), axis=0)

​                        t += 1

​                centroid[i] = np.mean(feature_test, axis=0, keepdims=True)



​            \# Compute one hot vector

​            t = 0

​            labels = np.zeros((feature.shape[0], num_clusters[k]), dtype=np.float32)

​            for i in range(feature.shape[0]):

​                if clus_labels[pred_labels[i]] == train_labels[i]:

​                    labels[i, pred_labels[i]] = 1

​                else:

​                    distance_assigned = euclidean_distances(feature[i].reshape(1, -1),

​                                                            centroid[pred_labels[i]].reshape(1, -1))

​                    cluster_special = [j for j in range(num_clusters[k]) if clus_labels[j] == train_labels[i]]

​                    distance = np.zeros(len(cluster_special))

​                    for j in range(len(cluster_special)):

​                        distance[j] = euclidean_distances(feature[i].reshape(1, -1),

​                                                          centroid[cluster_special[j]].reshape(1, -1))

​                    labels[i, cluster_special[np.argmin(distance)]] = 1



​            \# least square regression

​            A = np.ones((feature.shape[0], 1), dtype=np.float32)

​            feature = np.concatenate((A, feature), axis=1)

​            weight = np.matmul(LA.pinv(feature), labels)

​            feature = np.matmul(feature, weight)

​            print ('weight {}  dtype: {} '.format(i, weight.dtype))

​            print ('weights save....')

​            weights['%d LLSR weight' % k] = weight[1:weight.shape[0]]

​            print ('weights saved!')

​            bias['%d LLSR bias' % k] = weight[0].reshape(1, -1)

​            print(k, ' layer LSR weight shape:', weight.shape)

​            print(k, ' layer LSR output shape:', feature.shape)



​            pred_labels = np.argmax(feature, axis=1)

​            num_clas = np.zeros((num_clusters[k], use_classes), dtype=np.float32)

​            for i in range(num_clusters[k]):

​                for t in range(use_classes):

​                    for j in range(feature.shape[0]):

​                        if pred_labels[j] == i and train_labels[j] == t:

​                            num_clas[i, t] += 1

​            acc_train = np.sum(np.amax(num_clas, axis=1)) / feature.shape[0]

​            print(k, ' layer LSR training acc is {}'.format(acc_train))



​            \# Relu

​            for i in range(feature.shape[0]):

​                for j in range(feature.shape[1]):

​                    if feature[i, j] < 0:

​                        feature[i, j] = 0



​                        \# # Double relu

​                        \# for i in range(feature.shape[0]):

​                        \# 	for j in range(feature.shape[1]):

​                        \# 		if feature[i,j]<0:

​                        \# 			feature[i,j]=0

​                        \# 		elif feature[i,j]>1:

​                        \# 			feature[i,j]=1

​        else:

​            \# least square regression

​            labels = keras.utils.to_categorical(train_labels, 10)

​            A = np.ones((feature.shape[0], 1), dtype=np.float32)

​            feature = np.concatenate((A, feature), axis=1)

​            weight = np.matmul(LA.pinv(feature), labels).astype(np.float32)

​            print ('weight {}  dtype: {} '.format(i, weight.dtype))

​            feature = np.matmul(feature, weight)

​            weights['%d LLSR weight' % k] = weight[1:weight.shape[0]]

​            bias['%d LLSR bias' % k] = weight[0].reshape(1, -1)

​            print(k, ' layer LSR weight shape:', weight.shape)

​            print(k, ' layer LSR output shape:', feature.shape)



​            pred_labels = np.argmax(feature, axis=1)

​            acc_train = sklearn.metrics.accuracy_score(train_labels, pred_labels)

​            print('training acc is {}'.format(acc_train))

​    \# save data

​    fw = open('llsr_weights_compact_v2.pkl', 'wb')

​    pickle.dump(weights, fw, protocol=2)

​    fw.close()

​    fw = open('llsr_bias_compact_v2.pkl', 'wb')

​    pickle.dump(bias, fw, protocol=2)

​    fw.close()





if __name__ == '__main__':

​    main()



import numpy as np

from skimage.util.shape import view_as_windows



from sklearn.decomposition import PCA

from numpy import linalg as LA

from skimage.measure import block_reduce



import matplotlib.pyplot as plt

from itertools import product





def parse_list_string(list_string):

​    """Convert the class string to list."""

​    elem_groups = list_string.split(",")

​    results = []

​    for group in elem_groups:

​        term = group.split("-")

​        if len(term) == 1:

​            results.append(int(term[0]))

​        else:

​            start = int(term[0])

​            end = int(term[1])

​            results += range(start, end + 1)

​    return results





\# convert responses to patches representation

def window_process(samples, kernel_size, stride):

​    '''

​    Create patches

​    :param samples: [num_samples, feature_height, feature_width, feature_channel]

​    :param kernel_size: int i.e. patch size

​    :param stride: int

​    :return patches: flattened, [num_samples, output_h, output_w, feature_channel*kernel_size^2]



​    '''

​    n, h, w, c = samples.shape

​    output_h = (h - kernel_size) // stride + 1

​    output_w = (w - kernel_size) // stride + 1

​    patches = view_as_windows(samples, (1, kernel_size, kernel_size, c), step=(1, stride, stride, c))

​    patches = patches.reshape(n, output_h, output_w, c * kernel_size * kernel_size)

​    return patches





def window_process2(samples, kernel_size, stride):

​    n, c, h, w= samples.shape

​    output_h = (h - kernel_size) // stride + 1

​    output_w = (w - kernel_size) // stride + 1

​    \# samples2=np.moveaxis(samples, 3, 1)

​    patches=view_as_windows(samples, (1, c, kernel_size, kernel_size), step=(1, c, stride, stride))

​    patches=patches.reshape(n,output_h, output_w, c*kernel_size*kernel_size)

​    return patches





def window_process3(samples, kernel_size, stride):

​    n, c, h, w=samples.shape

​    print (samples.shape)

​    out_h=(h-kernel_size)//stride+1

​    out_w=(w-kernel_size)//stride+1

​    idx1 = range(0, h-kernel_size+1, 1)

​    print (idx1)

​    idx2 = [i + kernel_size  for i in idx1]

​    print (idx2)

​    data_lattice = np.array([samples[:, :, i:j, k:l] for ((i, j), (k, l)) in product(zip(idx1, idx2), zip(idx1, idx2))])

​    print (data_lattice.shape)

​    data_lattice=np.moveaxis(data_lattice, 1,0)

​    patches=data_lattice.reshape(n,out_h, out_w, c*kernel_size*kernel_size )

​    return patches



def remove_mean(features, axis):

​    '''

​    Remove the dataset mean.

​    :param features [num_samples,...]

​    :param axis the axis to compute mean



​    '''

​    feature_mean = np.mean(features, axis=axis, keepdims=True)

​    feature_remove_mean = features - feature_mean

​    return feature_remove_mean, feature_mean





def select_balanced_subset(images, labels, use_num_images, use_classes):

​    '''

​    select equal number of images from each classes

​    '''

​    \# Shuffle

​    num_total = images.shape[0]

​    shuffle_idx = np.random.permutation(num_total)

​    images = images[shuffle_idx]

​    labels = labels[shuffle_idx]



​    num_class = len(use_classes)

​    num_per_class = int(use_num_images / num_class)

​    selected_images = np.zeros((use_num_images, images.shape[1], images.shape[2], images.shape[3]))

​    selected_labels = np.zeros(use_num_images)

​    for i in range(num_class):

​        images_in_class = images[labels == i]

​        selected_images[i * num_per_class:(i + 1) * num_per_class] = images_in_class[:num_per_class]

​        selected_labels[i * num_per_class:(i + 1) * num_per_class] = np.ones((num_per_class)) * i



​    \# Shuffle again

​    shuffle_idx = np.random.permutation(num_per_class * num_class)

​    selected_images = selected_images[shuffle_idx]

​    selected_labels = selected_labels[shuffle_idx]

​    \# For test

​    \# print(selected_images.shape)

​    \# print(selected_labels[0:10])

​    \# plt.figure()

​    \# for i in range (10):

​    \# 	img=selected_images[i,:,:,0]

​    \# 	plt.imshow(img)

​    \# 	plt.show()

​    return selected_images, selected_labels





def find_kernels_pca(samples, num_kernels, energy_percent):

​    '''

​    Do the PCA based on the provided samples.

​    If num_kernels is not set, will use energy_percent.

​    If neither is set, will preserve all kernels.



​    :param samples: [num_samples, feature_dimension]

​    :param num_kernels: num kernels to be preserved

​    :param energy_percent: the percent of energy to be preserved

​    :return: kernels, sample_mean

​    '''

​    if num_kernels:

​        num_components = num_kernels

​        pca = PCA(n_components=num_components, svd_solver='full')

​    else:

​        pca = PCA(n_components=samples.shape[1], svd_solver='full')



​    pca.fit(samples)



​    \# Compute the number of kernels corresponding to preserved energy

​    if energy_percent:

​        energy = np.cumsum(pca.explained_variance_ratio_)

​        num_components = np.sum(energy < energy_percent) + 1



​    kernels = pca.components_[:num_components, :]

​    mean = pca.mean_



​    print("Num of kernels: %d" % num_components)

​    print("Energy percent: %f" % np.cumsum(pca.explained_variance_ratio_)[num_components - 1])

​    return kernels, mean





def multi_Saab_transform(images, labels, kernel_sizes, num_kernels, energy_percent, use_num_images, use_classes):

​    '''

​    Do the PCA "training".

​    :param images: [num_images, height, width, channel]

​    :param labels: [num_images]

​    :param kernel_sizes: list, kernel size for each stage,

​           the length defines how many stages conducted

​    :param num_kernels: list the number of kernels for each stage,

​           the length should be equal to kernel_sizes.

​    :param energy_percent: the energy percent to be kept in all PCA stages.

​           if num_kernels is set, energy_percent will be ignored.

​    :param use_num_images: use a subset of train images

​    :param use_classes: the classes of train images

​    return: pca_params: PCA kernels and mean

​    '''

​    num_total_images = images.shape[0]

​    if use_num_images < num_total_images and use_num_images > 0:

​        sample_images, selected_labels = select_balanced_subset(images, labels, use_num_images, use_classes)

​    else:

​        sample_images = images

​    \# sample_images=images

​    num_samples = sample_images.shape[0]

​    num_layers = len(kernel_sizes)

​    pca_params = {}

​    pca_params['num_layers'] = num_layers

​    pca_params['kernel_size'] = kernel_sizes



​    for i in range(num_layers):

​        print('--------stage %d --------' % i)

​        \# Create patches

​        \# sample_patches=window_process(sample_images,kernel_sizes[i],kernel_sizes[i]) # nonoverlapping

​        \# sample_patches = window_process(sample_images, kernel_sizes[i], 1)  # overlapping

​        sample_patches = window_process2(sample_images, kernel_sizes[i], 4)  # overlapping

​        h = sample_patches.shape[1]

​        w = sample_patches.shape[2]

​        \# Flatten

​        sample_patches = sample_patches.reshape([-1, sample_patches.shape[-1]])



​        \# Remove feature mean (Set E(X)=0 for each dimension)

​        sample_patches_centered, feature_expectation = remove_mean(sample_patches, axis=0)

​        \# print 'sample_patches_centered.shape: {}'.format(sample_patches_centered.shape)



​        \# Remove patch mean

​        training_data, dc = remove_mean(sample_patches_centered, axis=1)

​        print ('training_data.shape: {}'.format(training_data.shape))



​        \# Compute PCA kernel



​        if not num_kernels is None:

​            num_kernel = num_kernels[i]

​        kernels, mean = find_kernels_pca(training_data, num_kernel, energy_percent)



​        \# Add DC kernel

​        \# num_channels = sample_patches.shape[-1]

​        num_channels = sample_patches.shape[1]

​        dc_kernel = 1 / np.sqrt(num_channels) * np.ones((1, num_channels))

​        kernels = np.concatenate((dc_kernel, kernels), axis=0)



​        if i == 0:

​            \# Transform to get data for the next stage

​            \# print 'sample_patches_centered: {}'.format(sample_patches_centered)

​            transformed = np.matmul(sample_patches_centered, np.transpose(kernels))

​        else:

​            \# Compute bias term

​            bias = LA.norm(sample_patches, axis=1)

​            bias = np.max(bias)

​            pca_params['Layer_%d/bias' % i] = bias

​            \# Add bias

​            sample_patches_centered_w_bias = sample_patches_centered + 1 / np.sqrt(num_channels) * bias

​            \# Transform to get data for the next stage

​            transformed = np.matmul(sample_patches_centered_w_bias, np.transpose(kernels))

​            \# Remove bias

​            e = np.zeros((1, kernels.shape[0]))

​            e[0, 0] = 1

​            transformed -= bias * e



​        \# Reshape: place back as a 4-D feature map

​        sample_images = transformed.reshape(num_samples, h, w, -1)

​        sample_images=np.moveaxis(sample_images, 3,1)

​        \# sample_images = transformed.reshape(num_samples, -1, h, w)



​        \# Maxpooling

​        \# sample_images = block_reduce(sample_images, (1, 2, 2, 1), np.max)

​        sample_images = block_reduce(sample_images, (1, 1, 2, 2), np.max)



​        print('Sample patches shape after flatten:', sample_patches.shape)

​        print('Kernel shape:', kernels.shape)

​        print('Transformed shape:', transformed.shape)

​        print('Sample images shape:', sample_images.shape)



​        pca_params['Layer_%d/feature_expectation' % i] = feature_expectation

​        pca_params['Layer_%d/kernel' % i] = kernels

​        pca_params['Layer_%d/pca_mean' % i] = mean



​    return pca_params





\# Initialize

def initialize(sample_images, pca_params):

​    num_layers = pca_params['num_layers']

​    kernel_sizes = pca_params['kernel_size']



​    for i in range(num_layers):

​        print('--------stage %d --------' % i)

​        \# Extract parameters

​        feature_expectation = pca_params['Layer_%d/feature_expectation' % i].astype(np.float32)

​        kernels = pca_params['Layer_%d/kernel' % i].astype(np.float32)

​        \# mean = pca_params['Layer_%d/pca_mean' % i].astype(np.float32)

​        print ('sample images shape: {}'.format(sample_images.shape))

​        \# Create patches

​        \# print 'sample_images {}: {}', sample_images.shape, sample_images[-2:]

​        if i==0:

​            sample_patches = window_process2(sample_images, kernel_sizes[i], 4)  # overlapping

​            print ('sample_patches1: {}'.format(sample_patches.shape))

​        elif i==1:

​            sample_patches=window_process3(sample_images, kernel_sizes[i], 4)

​            print ('sample_patches1: {}'.format(sample_patches.shape))



​        h = sample_patches.shape[1]

​        w = sample_patches.shape[2]

​        \# Flatten

​        \# (n*output_h*output_w, c*kernel_size*kernel_size)

​        sample_patches = sample_patches.reshape([-1, sample_patches.shape[-1]])

​        print ('sample_patches2: {}'.format(sample_patches.shape))







​        \# Remove feature mean (Set E(X)=0 for each dimension)

​        \# feature after removing mean, mean

​        \# sample_patches_centered, feature_expectation = remove_mean(sample_patches, axis=0)

​        sample_patches_centered = sample_patches - feature_expectation

​        \# sample_patches_centered = sample_patches



​         \# sample_patches_centered=sample_patches-feature_expectation



​        \# Remove patch mean

​        \# training_data, dc = remove_mean(sample_patches_centered, axis=1)



​        \# num_channels = sample_patches.shape[-1]

​        if i == 0:

​            \# Transform to get data for the next stage

​            \# print 'train data:{}'.format(sample_patches_centered[:5])

​            \# print 'sample shape: {}'.format(sample_patches_centered.shape)

​            \# print 'data shape: {}'.format(sample_patches_centered.shape)

​            \# print 'kernels: {}, shape:{}'.format(kernels, kernels.shape)

​            \# print 'kernel: {} /{}'.format(kernels, kernels.dtype)

​            transformed = np.matmul(sample_patches_centered, np.transpose(kernels))

​            \# temp=transformed.reshape(10000, 28, 28, 6)

​            \# temp=np.moveaxis(temp, 3, 1)

​            \# print 'layer conv1 output: {}, shape: {}'.format( temp[:1].shape, temp[:1])

​        \# elif i==1:

​        \#     transformed= np.matmul(sample_patches_centered, np.transpose(kernels))

​        \#     temp=transformed.reshape(10000, 10, 10, 16)

​        \#     temp=np.moveaxis(temp, 3,1)

​        \#     print 'conv2  {},output: {}'.format(temp[:1].shape, temp[:1])

​        else:

​            \# weight=(kernels)

​            \# print 'conv2 temp_bias: ', np.matmul(-1*feature_expectation, weight)

​            \# print 'conv2 kernel: {}, shape: {}'.format(kernels, kernels.shape)

​            \# print 'sample_patches_centered: ',sample_patches_centered.shape

​            bias = pca_params['Layer_%d/bias' % i].astype(np.float32)

​            \# Add bias

​            \# print 'num_channels: {}'.format(num_channels)

​            sample_patches_centered_w_bias = sample_patches_centered + 1 / np.sqrt(150) * bias

​            \# bias1_tmp=np.zeros(150)+1/np.sqrt(num_channels)* bias

​            \# print 'conv2 bias1: ', np.matmul(bias1_tmp, weight)

​            \# Transform to get data for the next stage

​            transformed = np.matmul(sample_patches_centered_w_bias, np.transpose(kernels))

​            \# Remove bias

​            e = np.zeros((1, kernels.shape[0]),dtype=np.float32)

​            e[0, 0] = 1

​            transformed -= bias * e

​            \# print 'conv2 bias2: ', -bias*e

​            \# print 'bias: {}'.format(bias)

​            \# temp=transformed.reshape(10000, 10, 10, 16)

​            \# temp=np.moveaxis(temp, 3, 1)

​            \# print 'conv2_2 shape {}, output: {}'.format(temp[:1].shape, temp[:1])



​        \# Reshape: place back as a 4-D feature map

​        num_samples = sample_images.shape[0]

​        sample_images = transformed.reshape(num_samples, h, w, -1)

​        sample_images=np.moveaxis(sample_images, 3, 1)

​        \# sample_images = transformed.reshape(num_samples, -1, h, w)

​        \# print 'sample_images1.shape: {}'.format(sample_images.shape)



​        \# Maxpooling

​        \# sample_images = block_reduce(sample_images, (1, 2, 2, 1), np.max)

​        sample_images = block_reduce(sample_images, (1, 1, 2, 2), np.max)

​        \# print 'Maxpool2D {}/ shape:{} / value: {} '.format(i, sample_images[:1].shape, sample_images[:1])



​        print('Sample patches shape after flatten:', sample_patches.shape)

​        print('Kernel shape:', kernels.shape)

​        print('Transformed shape:', transformed.shape)

​        print('Sample images shape:', sample_images.shape)

​    return sample_images

import pickle
import numpy as np
import cv2
from skimage.util.shape import view_as_windows
import data
from tensorflow.python.platform import flags



def Compute_PSNR(img, img_reconst):
   #  output PSNR
   mse = np.mean(np.square(img_reconst-img))
   psnr =10*np.log10(255**2/mse)
   return psnr
   

def getfeature(img,k0,k1,b1):
   patch = view_as_windows(img,(4, 4),step=(4, 4)).reshape(8,8,16)

   patch = np.dot(patch, np.transpose(k0)) ## reduce dim
   print("Shape of patch in 1st stage :", patch.shape)

   patch_s2 = view_as_windows(patch.copy(),(4,4,1),step=(4,4,1))
   patch_s2 = patch_s2.reshape(2,2,s1 * 16)

   patch_s2 = patch_s2 + 1 / np.sqrt(s1 * s2) * b1
   patch_s2 = np.dot(patch_s2, np.transpose(k1))
   print("Shape of patch in 2nd stage :", patch_s2.shape)
   
   return patch_s2
   
def compute_inv(patch_s2,s1,s2,b1,k1,k0):
   inv_patch = np.dot(patch_s2, np.linalg.pinv(np.transpose(k1)))
   inv_patch = inv_patch - 1 / np.sqrt(s1*s2) * b1
   inv_patch = inv_patch.reshape(2,2,s1,16)
   inv_patch = np.moveaxis(inv_patch,2,3)
   print("Second stage inv_patch: ", inv_patch.shape)
   img_reconst_s1 = np.zeros((8,8,s1))

   for i in range(0,2):
      for j in range(0,2):
         for k in range(0,16):
            img_reconst_s1[i * 4 + k // 4,j * 4 + k % 4] = inv_patch[i][j][k]

   print("2nd stage reconstruct image: ", img_reconst_s1.shape)

   inv_patch = np.dot(img_reconst_s1, np.linalg.pinv(np.transpose(k0)))
   img_reconst = np.zeros((32,32))
   for i in range(0,8):
      for j in range(0,8):
         for k in range(0,16):
            img_reconst[i * 4 + k // 4, j * 4 + k % 4] = inv_patch[i][j][k]
   img_output = 255*(img_reconst-np.min(img_reconst))/(np.max(img_reconst)-np.min(img_reconst))
   
   return img_output



s1 = 6
s2 = 16

fr = open('./pca_params_compact.pkl', 'rb')
saab_weight = pickle.load(fr)
fr.close()

k0 = np.array(saab_weight['Layer_0/kernel'])
k1 = np.array(saab_weight['Layer_1/kernel'])

b1 = saab_weight['Layer_1/bias'].astype(np.float32)



img = cv2.imread('4.png',0)
patch_s2 = getfeature(img,k0,k1,b1)

img_output = compute_inv(patch_s2,s1,s2,b1,k1,k0)


#  save image
cv2.imwrite('_%d_%d.jpg'%(s1,s2),img_output)

psnr = Compute_PSNR(img, img_reconst);
print ( "The PSNR of reconstruct image is: ", psnr)

